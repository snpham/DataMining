{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f2e376-0dba-46c4-ae4a-6d132f63ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12977f61-637b-42c1-818c-f259e86b80a1",
   "metadata": {},
   "source": [
    "### apriori analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b2170b-a22e-46f0-ac09-3712bc583859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(dataset):\n",
    "    \"\"\"generator for removing spaces and separating\n",
    "    items with commas\n",
    "    \"\"\"\n",
    "    for row in dataset.iloc[:,0]:\n",
    "        yield row.replace(\" \", \"\").split(\",\")\n",
    "\n",
    "\n",
    "def row_gen(dataset):\n",
    "    \"\"\"generator for removing spaces and separating\n",
    "    items with commas\n",
    "    \"\"\"\n",
    "    for row in dataset:\n",
    "        yield row.replace(\" \", \"\").split(\",\")\n",
    "\n",
    "\n",
    "def threshold(data, min_sup):\n",
    "    \"\"\"get dictionary of counts of frequent items in data\n",
    "    \"\"\"\n",
    "    return {item:count for item, count in data.items() if count >= min_sup}\n",
    "\n",
    "\n",
    "def union_set(datadict):\n",
    "    \"\"\"joining individual items from previous itemset\n",
    "    \"\"\"\n",
    "    return set([','.join((i, j)) for i in datadict for j in datadict if i < j])\n",
    "\n",
    "\n",
    "def apriori(dataset, min_sup):\n",
    "    \"\"\"scan datasets for up to frequent 3-itemsets\n",
    "    \"\"\"\n",
    "    \n",
    "    freq1_items = set()\n",
    "    for data in data_gen(dataset):\n",
    "        for item in data:\n",
    "            freq1_items.add(item)\n",
    "\n",
    "    scan1 = dict.fromkeys(freq1_items, 0)\n",
    "    for data in data_gen(dataset):\n",
    "        for item in data:\n",
    "            scan1[item] += 1\n",
    "    scan1 = threshold(scan1, min_sup)\n",
    "    scan1 = dict(sorted(scan1.items()))\n",
    "\n",
    "    unionset1 = union_set(scan1)\n",
    "    scan2 = dict.fromkeys(unionset1, 0)\n",
    "    for data in data_gen(dataset):\n",
    "        for row in scan2:\n",
    "            if set(row.split(',')).issubset(set(data)):\n",
    "                scan2[row] += 1\n",
    "    scan2 = threshold(scan2, min_sup)\n",
    "    scan2 = dict(sorted(scan2.items()))\n",
    "\n",
    "    unionset2 = union_set(scan2)\n",
    "    newunion2 = set()\n",
    "    for row in unionset2:\n",
    "        newset = set(sorted(row.split(',')))\n",
    "        for col in row_gen(scan2):\n",
    "            if set(col).issubset(newset) and scan2[','.join(col)] >= 3 and len(newset) == 3:\n",
    "                newunion2.add(','.join(newset))\n",
    "    scan3 = dict.fromkeys(newunion2, 0)\n",
    "\n",
    "    for data in data_gen(dataset):\n",
    "        for row in scan3:\n",
    "            if set(row.split(',')).issubset(set(data)):\n",
    "                scan3[row] += 1\n",
    "    scan3 = threshold(scan3, min_sup)\n",
    "    scan3 = dict(sorted(scan3.items()))\n",
    "\n",
    "    print('frequent-1 itemset:', scan1)\n",
    "    print('frequent-2 itemset:', scan2)\n",
    "    print('frequent-3 itemset:', scan3)\n",
    "    \n",
    "    return scan1, scan2, scan3\n",
    "\n",
    "\n",
    "def apriori_assoc(df, datadict1, datadict2, label):\n",
    "\n",
    "    # support\n",
    "    splitlabel = label.split(',')\n",
    "    for key, _ in datadict2.items():\n",
    "        if set(splitlabel).issubset(key.split(',')):\n",
    "            labl = key\n",
    "        else:\n",
    "            continue\n",
    "    supp = datadict2[labl]/len(df.index)\n",
    "\n",
    "    # confidence\n",
    "    for key1, val1 in datadict1.items():\n",
    "        if set(splitlabel[:-1]).issubset(key1.split(',')):\n",
    "            for key2, val2 in datadict2.items():\n",
    "                if set(splitlabel).issubset(key2.split(',')):\n",
    "                    conf = val2/val1\n",
    "    string = f'{splitlabel[:-1]} -> {splitlabel[-1]}'\n",
    "    return string, supp, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691407e-37da-4179-ae24-4ad4c5aef4b1",
   "metadata": {},
   "source": [
    "#### apriori analysis examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0f1c3b-8916-4d9e-a58d-cb99fb1d5e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequent-1 itemset: {'A': 2, 'B': 3, 'C': 3, 'E': 3}\n",
      "frequent-2 itemset: {'A,C': 2, 'B,C': 2, 'B,E': 3, 'C,E': 2}\n",
      "frequent-3 itemset: {'E,B,C': 2}\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "dataset = pd.read_csv('datasets/apriori_ex.csv', index_col=0, header=0)\n",
    "min_sup = 0.50\n",
    "min_sup *= len(dataset)\n",
    "scan1, scan2, scan3 = apriori(dataset, min_sup)\n",
    "# itemset: {'E', 'D', 'C', 'A', 'B'}\n",
    "# frequent-1 itemset: {'A': 2, 'B': 3, 'C': 3, 'E': 3}\n",
    "# frequent-2 itemset: {'A,C': 2, 'B,C': 2, 'B,E': 3, 'C,E': 2}\n",
    "# frequent-3 itemset: {'C,B,E': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7ddd7b-0ca8-4c6f-9d66-dfc94239a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequent-1 itemset: {'B': 4, 'E': 3, 'G': 3, 'I': 3, 'N': 4, 'Z': 3}\n",
      "frequent-2 itemset: {'B,I': 3, 'B,N': 4, 'G,Z': 3, 'I,N': 3}\n",
      "frequent-3 itemset: {'N,B,I': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test 2\n",
    "dataset = pd.read_csv('datasets/apriori_ex2.csv', index_col=0, header=0)\n",
    "min_sup = 0.60\n",
    "min_sup *= len(dataset)\n",
    "scan1, scan2, scan3 = apriori(dataset, min_sup)\n",
    "# itemset: {'Z', 'N', 'B', 'E', 'D', 'I', 'T', 'O', 'G', 'S', 'F'}\n",
    "# frequent-1 itemset: {'B': 4, 'E': 3, 'G': 3, 'I': 3, 'N': 4, 'Z': 3}\n",
    "# frequent-2 itemset: {'B,I': 3, 'B,N': 4, 'G,Z': 3, 'I,N': 3}\n",
    "# frequent-3 itemset: {'I,B,N': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a2350a2-7f06-46e6-88d2-fe7770448a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequent-1 itemset: {'bread': 4, 'cheese': 3, 'milk': 4, 'pie': 3}\n",
      "frequent-2 itemset: {'bread,cheese': 3, 'bread,milk': 4, 'bread,pie': 3, 'cheese,milk': 3, 'milk,pie': 3}\n",
      "frequent-3 itemset: {'bread,cheese,milk': 3, 'pie,bread,milk': 3}\n"
     ]
    }
   ],
   "source": [
    "# test 3\n",
    "dataset = pd.read_csv('datasets/apriori_ex3.csv', index_col=0, header=0)\n",
    "min_sup = 0.60\n",
    "min_sup *= len(dataset)\n",
    "scan1, scan2, scan3 = apriori(dataset, min_sup)\n",
    "# itemset: {'pie', 'bread', 'cereal', 'cheese', 'milk', 'cherry'}\n",
    "# frequent-1 itemset: {'bread': 4, 'cheese': 3, 'milk': 4, 'pie': 3}\n",
    "# frequent-2 itemset: {'bread,cheese': 3, 'bread,milk': 4, 'bread,pie': 3, 'cheese,milk': 3, 'milk,pie': 3}\n",
    "# frequent-3 itemset: {'bread,cheese,milk': 3, 'pie,bread,milk': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3b3ec-c872-4f1f-ab18-d4855fb84f2c",
   "metadata": {},
   "source": [
    "#### association rules (support/confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e493f72a-a1eb-46f9-9c2a-53d5ebb54f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bread', 'milk'] -> pie support: 0.75 confidence: 0.75\n",
      "['milk', 'pie'] -> bread support: 0.75 confidence: 1.0\n",
      "['bread', 'pie'] -> milk support: 0.75 confidence: 1.0\n",
      "['bread', 'milk'] -> cheese support: 0.75 confidence: 0.75\n",
      "['cheese', 'milk'] -> bread support: 0.75 confidence: 1.0\n",
      "['bread', 'cheese'] -> milk support: 0.75 confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "# test 4\n",
    "# association rules\n",
    "tofind = ['bread,milk,pie', 'milk,pie,bread', 'bread,pie,milk', \n",
    "          'bread,milk,cheese','cheese,milk,bread', 'bread,cheese,milk']\n",
    "for sets in tofind:\n",
    "    assoc_str, supp, conf = apriori_assoc(df=dataset, datadict1=scan2, \n",
    "                                        datadict2=scan3, label=sets)\n",
    "    print(assoc_str, 'support:', supp, 'confidence:', conf)\n",
    "    # ['bread', 'milk'] -> pie support: 0.75 confidence: 0.75\n",
    "    # ['milk', 'pie'] -> bread support: 0.75 confidence: 1.0\n",
    "    # ['bread', 'pie'] -> milk support: 0.75 confidence: 1.0\n",
    "    # ['bread', 'milk'] -> cheese support: 0.75 confidence: 0.75\n",
    "    # ['cheese', 'milk'] -> bread support: 0.75 confidence: 1.0\n",
    "    # ['bread', 'cheese'] -> milk support: 0.75 confidence: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc6b00-3361-4a4b-9ed2-77e4a2128087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
